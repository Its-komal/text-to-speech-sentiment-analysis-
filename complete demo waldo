import speech_recognition as sr 
import pyttsx3
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from langdetect import detect
import time 
engine=pyttsx3.init()
r=sr.Recognizer()
def detect_intent_texts(project_id, session_id, texts, language_code="en-US"):
    from google.cloud import dialogflow
    session_client = dialogflow.SessionsClient()
    session = session_client.session_path(project_id, session_id)
    for text in texts:
        text_input = dialogflow.TextInput(text=text, language_code=language_code)
        query_input = dialogflow.QueryInput(text=text_input)
        response = session_client.detect_intent(
            request={"session": session, "query_input": query_input}
        )
        return(response.query_result.fulfillment_text)


with sr.Microphone() as source:
    print("Listening")
    audio_data = r.record(source, duration=5)
    print("Recognizing...")
    try:
        language= detect( r.recognize_google(audio_data))            
        text = r.recognize_google(audio_data, show_all = True, language='en-In' )
        print("I thinks you said: '" + r.recognize_google(audio_data) + "'")
        text_output=detect_intent_texts("neural-proton-321810","123456789",[text],)
    
    except:
        pass


import gtts  
from playsound import playsound  
import os

t1 = gtts.gTTS(detect_intent_texts("neural-proton-321810","123456789",[r.recognize_google(audio_data)]))   
t1.save("welcome.mp3")
os.system("welcome.mp3")
time.sleep(3)
os.remove("welcome.mp3")


import face_recognition as fr
import cv2

import numpy as np
import os
import datetime
print("Done")
#%%######################################################################################################################
path = "./train/"

known_names = []
known_name_encodings = []

images = os.listdir(path)

def training():
    for _ in images:
        image = fr.load_image_file(path + _)
        print("1")
        image_path = path + _
        encoding = fr.face_encodings(image)[0]
        known_name_encodings.append(encoding)
        known_names.append(os.path.splitext(os.path.basename(image_path))[0].capitalize())
    
    print(known_names)


    
def recoganizing():
    print("Streaming started")
    lst=[]
    video_capture = cv2.VideoCapture(1)
    while True:
        ret, frame = video_capture.read()
        name="Unknown"
        face_locations = fr.face_locations(frame)
        face_encodings = fr.face_encodings(frame, face_locations)
        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):
            matches = fr.compare_faces(known_name_encodings, face_encoding)
            name = ""

            face_distances = fr.face_distance(known_name_encodings, face_encoding)
            best_match = np.argmin(face_distances)

            if matches[best_match]:
                name = known_names[best_match]
                final=name
            else:
                name="Unknown"





            

            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)
            cv2.rectangle(frame, (left, bottom - 15), (right, bottom), (0, 0, 255), cv2.FILLED)
            

            font = cv2.FONT_HERSHEY_DUPLEX
            cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)

        cv2.imshow("Result", frame)


  
        # saving((left,bottom - 15] (right, bottom))
        # if name=="Unknown":
        #     for (x,y,w,h) in faces:
        #         cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 2)     
                
        # Save the captured image into the datasets folder
        # cv2.imwrite("./output.jpg", frame)

        if name!="Unknown":
            break


        elif name=="Unknown":
            print("You are unknown so plezz enter your name")
            your_name=input()
            cv2.imwrite("/train/" + str(your_name) + ".jpg", frame[left:left+right,top:top+bottom])
            break

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    print(final)
    video_capture.release()
    cv2.waitKey(0)
    cv2.destroyAllWindows()

    return(name)
# %%


training()
final=recoganizing()
t1 = gtts.gTTS("Nahi ho raha kya" + final)   
t1.save("greet.mp3")
os.system("greet.mp3")
time.sleep(3)
os.remove("greet.mp3")
